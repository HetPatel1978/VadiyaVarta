{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Words: so I have a fever and I also I am feeling dizzy so can you please help me with that\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import wave\n",
    "import pyaudio\n",
    "import threading\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Function to handle live video feed with audio recording\n",
    "def live_video_with_audio_recording(output_audio_path, record_time=10):\n",
    "    def record_audio():\n",
    "        \"\"\"Record audio from the microphone.\"\"\"\n",
    "        chunk = 1024\n",
    "        sample_format = pyaudio.paInt16\n",
    "        channels = 1\n",
    "        rate = 16000\n",
    "\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=sample_format, channels=channels, rate=rate, input=True, frames_per_buffer=chunk)\n",
    "\n",
    "        frames = []\n",
    "        for _ in range(0, int(rate / chunk * record_time)):\n",
    "            data = stream.read(chunk)\n",
    "            frames.append(data)\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        # Save recorded audio to a file\n",
    "        with wave.open(output_audio_path, 'wb') as wf:\n",
    "            wf.setnchannels(channels)\n",
    "            wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "            wf.setframerate(rate)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "\n",
    "    # Start video feed\n",
    "    capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # Record audio in a separate thread\n",
    "    audio_thread = threading.Thread(target=record_audio)\n",
    "    audio_thread.start()\n",
    "\n",
    "    while audio_thread.is_alive():  # Keep showing video feed while recording audio\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow(\"Live Video Feed\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    audio_thread.join()\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to transcribe audio to text\n",
    "def audio_to_text(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(\"Extracted Words:\", text)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Could not understand the audio.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "\n",
    "# Main Execution for Live Video\n",
    "if __name__ == \"__main__\":\n",
    "    time.sleep(5)  # Countdown before starting\n",
    "    audio_file_live = \"live_audio.wav\"\n",
    "    live_video_with_audio_recording(audio_file_live, record_time=10)\n",
    "    audio_to_text(audio_file_live)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
