import torch
import joblib
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from datasets import Dataset
from sklearn.model_selection import train_test_split
import pandas as pd

# âœ… Step 1: Load Processed Dataset
print("ðŸ”¹ Loading processed dataset...")
dataset_path = r"C:/Users/peter/Desktop/het/Vadiya Varta/Model-3/balanced_dataset.csv"
df = pd.read_csv(dataset_path)

# âœ… Step 2: Load Label Encoder
label_encoder_path = r"C:/Users/peter/Desktop/het/Vadiya Varta/label_encoder.joblib"
label_encoder = joblib.load(label_encoder_path)
num_labels = len(label_encoder.classes_)

# âœ… Step 3: Split Data into Test Set
test_texts = df["All_Symptoms"]
test_labels = df["label"]

# âœ… Step 4: Load BioBERT Tokenizer and Model
model_name = "monologg/biobert_v1.1_pubmed"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model_path = "C:\Users\peter\Desktop\het\Vadiya Varta\Model-3\checkpoints\checkpoint-100000"
model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)

# âœ… Step 5: Tokenize Test Data
def tokenize_data(texts):
    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors="pt")

test_encodings = tokenize_data(list(test_texts))

# âœ… Step 6: Create Dataset for Evaluation
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
test_dataset = Dataset.from_dict({
    "input_ids": test_encodings["input_ids"].to(device),
    "attention_mask": test_encodings["attention_mask"].to(device),
    "labels": torch.tensor(test_labels.values, dtype=torch.long).to(device)
})

# âœ… Step 7: Define Performance Metrics
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    acc = accuracy_score(labels, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average="weighted")
    return {"accuracy": acc, "precision": precision, "recall": recall, "f1": f1}

# âœ… Step 8: Set Up Trainer for Evaluation
from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./biobert_results",  # Specify directory for saving outputs
    per_device_eval_batch_size=16,   # Adjust based on GPU memory
    no_cuda=False,
    logging_dir='./logs',  # Directory for logs
    evaluation_strategy="epoch",  # Evaluate after every epoch
    fp16=True  # Mixed precision for faster evaluation on GPUs
)

trainer = Trainer(
    model=model,
    args=training_args,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
)

# âœ… Step 9: Run Evaluation
print("ðŸš€ Evaluating model...")
eval_results = trainer.evaluate()

# âœ… Step 10: Print Evaluation Results
print("ðŸ”¹ Evaluation Results:")
print(f"Accuracy: {eval_results['eval_accuracy']:.4f}")
print(f"Precision: {eval_results['eval_precision']:.4f}")
print(f"Recall: {eval_results['eval_recall']:.4f}")
print(f"F1-Score: {eval_results['eval_f1']:.4f}")

# âœ… Step 11: Save the Evaluation Results to a File (optional)
with open("evaluation_results.txt", "w") as f:
    f.write(f"Accuracy: {eval_results['eval_accuracy']:.4f}\n")
    f.write(f"Precision: {eval_results['eval_precision']:.4f}\n")
    f.write(f"Recall: {eval_results['eval_recall']:.4f}\n")
    f.write(f"F1-Score: {eval_results['eval_f1']:.4f}\n")

print("âœ… Evaluation completed and saved to `evaluation_results.txt`.")






















# import torch
# import pandas as pd
# import joblib
# import matplotlib.pyplot as plt
# from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer
# from datasets import Dataset
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import accuracy_score, precision_recall_fscore_support
# import numpy as np

# # âœ… Step 1: Load Processed Dataset
# print("ðŸ”¹ Loading processed dataset for evaluation...")
# dataset_path = r"C:/Users/peter/Desktop/het/Vadiya Varta/Model-3/balanced_dataset.csv"
# df = pd.read_csv(dataset_path)

# # âœ… Step 2: Load Label Encoder
# label_encoder_path = r"C:\Users\peter\Desktop\het\Vadiya Varta\Model-3\label_encoder.joblib"
# label_encoder = joblib.load(label_encoder_path)
# num_labels = len(label_encoder.classes_)

# # âœ… Step 3: Split Data into Train & Test Sets (Only Using Test Data Here)
# _, test_texts, _, test_labels = train_test_split(
#     df["All_Symptoms"], df["label"], test_size=0.2, random_state=42
# )

# # âœ… Step 4: Load BioBERT Tokenizer
# model_name = "monologg/biobert_v1.1_pubmed"
# tokenizer = AutoTokenizer.from_pretrained(model_name)

# # âœ… Step 5: Tokenize Test Texts
# def tokenize_data(texts):
#     return tokenizer(texts, padding="max_length", truncation=True, max_length=128, return_tensors="pt")

# print("ðŸ”¹ Tokenizing test data...")
# test_encodings = tokenize_data(list(test_texts))

# # âœ… Step 6: Move Data to CUDA (If Available)
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# print(f"ðŸš€ Using device: {device}")

# test_dataset = Dataset.from_dict({
#     "input_ids": test_encodings["input_ids"],
#     "attention_mask": test_encodings["attention_mask"],
#     "labels": torch.tensor(test_labels.values, dtype=torch.long),
# })

# # âœ… Step 7: Load **Saved Checkpoint**
# checkpoint_path = r"C:/Users/peter/Desktop/het/Vadiya Varta/Model-3/checkpoints/checkpoint-100000"
# print(f"ðŸ”¹ Loading checkpoint from {checkpoint_path}...")

# model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path, num_labels=num_labels).to(device)

# # âœ… Step 8: Define Performance Metrics
# def compute_metrics(pred):
#     labels = pred.label_ids
#     preds = pred.predictions.argmax(-1)
#     acc = accuracy_score(labels, preds)
#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average="weighted", zero_division=1)
#     return {"accuracy": acc, "precision": precision, "recall": recall, "f1": f1}

# # âœ… Step 9: Set Up Trainer for Evaluation
# trainer = Trainer(
#     model=model,
#     eval_dataset=test_dataset,
#     compute_metrics=compute_metrics,
# )

# # âœ… Step 10: Run Evaluation
# print("ðŸš€ Evaluating model performance...")
# metrics = trainer.evaluate()
# print("âœ… Model Evaluation Complete!")
# print(metrics)

# # âœ… Step 11: Generate Graphs for Visualization
# def plot_metrics(metrics):
#     categories = ['Accuracy', 'Precision', 'Recall', 'F1-score']
#     values = [metrics['eval_accuracy'], metrics['eval_precision'], metrics['eval_recall'], metrics['eval_f1']]

#     plt.figure(figsize=(8, 5))
#     plt.bar(categories, values, color=['blue', 'green', 'red', 'purple'])
#     plt.ylim(0, 1)
#     plt.ylabel("Score")
#     plt.title("Model Performance Metrics")
#     for i, v in enumerate(values):
#         plt.text(i, v + 0.02, f"{v:.2f}", ha='center', fontsize=12)
#     plt.show()

# # âœ… Step 12: Plot Metrics
# plot_metrics(metrics)
